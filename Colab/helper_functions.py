# -*- coding: utf-8 -*-
"""helper_functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IH6WTi0G-TM0m5mwimNfCEbm740g7e_G
"""

import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm
from matplotlib import font_manager
import seaborn as sns
import itertools
import random as rd

import PIL.Image
import cv2
import shutil
import PIL
import os
from pathlib import Path

from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.preprocessing import label_binarize, LabelEncoder, LabelBinarizer

import tensorflow as tf
from keras.src import layers
import keras

'''
    Modify ล่าสุด 01/02/2025
'''

"ฟังก์ชันสำหรับทำงานกับภาพโดยเฉพาะ"
"Source: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
def walk_through_dir(dir_path):
    """
    Walks through dir_path returning its contents.

    Args:
        dir_path (str): target directory

    Returns:
        A print out of:
        number of subdiretories in dir_path
        number of images (files) in each subdirectory
        name of each subdirectory
    """
    for dirpath, dirnames, filenames in os.walk(dir_path):
        print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

def verify_images(path):
    '''
    Function นี้ใช้สำหรับตรวจสอบรูปภาพว่าเปิดได้หรือไม่
    '''
    valid_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']
    path = [Path(path).rglob(ext) for ext in valid_extensions]
    path = [p for sublist in path for p in sublist]
    valid_count = 0
    invalid_count = 0

    for img_path in path:
      print(f"Checking: {img_path} Done")
      try:
        img = PIL.Image.open(img_path)
        valid_count += 1
      except PIL.UnidentifiedImageError:
        invalid_count += 1
        print(f"Unidentified Image Path: {img_path}")

    print(f"Total valid images: {valid_count}")
    print(f"Total invalid images: {invalid_count}")

def mapping(selector):
    '''
    ฟังก์ชันนี้ใช้สำหรับ Map ชื่อ Label กับตัวเลขกำกับรูปภาพ
    selector คือ ตัวเลือกในการใช้ Dict Match ตัวเลขรูปภาพกับ Class ให้เหมาะสม
    '''
    if selector == "maizeDataset5Classes":
      labels_mapping = {
          '1': "Phaeosphaeria spot",
          '2': "Corn Eyespot",
          '3': "Gray Leaf Spot",
          '4': "Goss's Bacterial wilt",
          '5': "Southern Rusts"
      }

    elif selector == "maizeDataset4Classes":
      labels_mapping = {
          '1': "Phaeosphaeria spot",
          '2': "Corn Eyespot",
          '3': "Gray Leaf Spot",
          '4': "Goss's Bacterial wilt"
      }

    elif selector == "riceDataset":
      labels_mapping = {
          '1': 'Rice Stackburn',
          '2': 'Rice Leaf Smut',
          '4': 'Rice Leaf Scald',
          '8': 'Rice White Tip',
          '25': 'Bacterial Leaf Streak'
      }

    else:
      print("Your's options is not match try again!")
      return None

    return labels_mapping

def to_dataframe(path, mode="single", condition=False, labels_mapping=None):
    '''
    แปลงรูปภาพในโฟลเดอร์เป็น DataFrame
        - mode="single": สำหรับ Dataset ที่แบ่งภาพเป็น Class แยกตามโฟลเดอร์
        - mode="multi": สำหรับ Dataset ที่ยังไม่มีการแบ่ง Class และใช้การ Map Label จากชื่อไฟล์
        - condition=True: เงื่อนไขสำหรับการกรอง Class ออกจาก Dataset (ใช้ในโหมด multi)

        dataset/
        ├── class1/
        │   ├── img1.jpg
        │   └── img2.jpg
        ├── class2/
        │   ├── img3.jpg
        │   └── img4.jpg


        Dataframe Structure Sample
        Filepath	                |   Label
        ────────────────────────────────────────
        dataset/class1/img1.jpg	    |   class1
    '''
    directory = Path(path)
    file_extensions = ['*.JPG', '*.jpg', '*.PNG', '*.png', '*.JPEG', '*.jpeg']
    paths = list(itertools.chain(*[directory.glob(f'**/{ext}') for ext in file_extensions]))

    if not paths:
        print("Error: No image files found in the directory.")
        return None

    if mode == "single":
        labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], paths))
    elif mode == "multi":
        if condition:
            paths = list(filter(lambda x: not x.name.startswith('5'), paths))
        if labels_mapping is None:
            raise ValueError("Error: 'labels_mapping' is required for mode='multi'. Please provide a valid mapping.")
        labels = [labels_mapping.get(path.name.split('_')[0], 'Unknown') for path in paths]
    else:
        raise ValueError("Error: Invalid mode. Choose 'single' or 'multi'.")

    paths = pd.Series(paths, name='Filepath').astype(str)
    labels = pd.Series(labels, name='Label')
    df = pd.concat([paths, labels], axis=1)

    print(f"Total images: {len(df)}")
    print(f"Total classes: {df['Label'].nunique()}")

    return df

def to_dataframe_excel(path, sheet_name='Sheet1', mode='single', condition=False, labels_mapping=None, skip=True):
    '''
    แปลงข้อมูลจาก Excel เป็น DataFrame และตรวจสอบความถูกต้องของ Path พร้อมรองรับ Condition และ Header
        - path: เส้นทางไฟล์ Excel
        - sheet_name: ชื่อ Sheet ใน Excel ที่ต้องการอ่าน
        - labels_mapping: Dictionary สำหรับ Map Label (ใช้ในโหมด multi)
        - mode="single": ใช้ Label ที่มีอยู่ใน Excel
        - mode="multi": Map Label จากชื่อไฟล์
        - condition: ฟังก์ชันกรอง Path สำหรับโหมด multi
        - skip: กำหนดว่าควรอ่าน Header หรือไม่ (ค่าเริ่มต้น=True)
    Returns:
        train_df, valid_df: ถ้ามีแค่ train_paths และ val_paths
        train_df, valid_df, test_df: ถ้ามีทั้ง train_paths, val_paths, และ test_paths

    ตัวอย่างข้อมูลในไฟล์ Excel:
    | Train_Index | Train_Paths               | Validation_Index | Validation_Paths           | Test_Index | Test_Paths              |
    |-------------|---------------------------|------------------|----------------------------|------------|-------------------------|
    | 1           | /path/to/train/img1.jpg   | 1                | /path/to/val/img1.jpg      | 1          | /path/to/test/img1.jpg  |
    | 2           | /path/to/train/img2.jpg   | 2                | /path/to/val/img2.jpg      | 2          | /path/to/test/img2.jpg  |
    | 3           | /path/to/train/img3.jpg   | 3                | /path/to/val/img3.jpg      | 3          |                         |

    ผลลัพธ์:
    train_df:
    | Filepath                | Label      | Original_Index |
    |-------------------------|------------|----------------|
    | /path/to/train/img1.jpg | Class 1    | 1              |
    | /path/to/train/img2.jpg | Class 2    | 2              |
    | /path/to/train/img3.jpg | Class 3    | 3              |

    valid_df:
    | Filepath                | Label      | Original_Index |
    |-------------------------|------------|----------------|
    | /path/to/val/img1.jpg   | Class 1    | 1              |
    | /path/to/val/img2.jpg   | Class 2    | 2              |
    | /path/to/val/img3.jpg   | Class 3    | 3              |

    test_df:
    | Filepath                | Label      | Original_Index |
    |-------------------------|------------|----------------|
    | /path/to/test/img1.jpg  | Class 1    | 1              |
    | /path/to/test/img2.jpg  | Class 2    | 2              |
    '''

    header_option = 0 if skip else None
    data = pd.read_excel(path, sheet_name=sheet_name, header=header_option)

    required_columns = ['Train_Paths', 'Validation_Paths', 'Test_Paths']
    available_columns = [col for col in required_columns if col in data.columns]
    if not available_columns:
        raise ValueError("Error: Excel file must contain at least one of 'Train_Paths', 'Validation_Paths', or 'Test_Paths' columns.")

    def create_df(paths_col, index_col, mode, condition, labels_mapping):
        if paths_col not in data.columns or index_col not in data.columns:
            return None

        paths = data[paths_col].dropna().tolist()

        valid_paths = [path for path in paths if os.path.exists(path)]
        missing_paths = [path for path in paths if not os.path.exists(path)]

        if missing_paths:
            print(f"Warning: {len(missing_paths)} file(s) in '{paths_col}' do not exist.")
            print(missing_paths)

        if mode == 'multi' and condition:
            valid_paths = list(filter(condition, valid_paths))

        if mode == "single":
            labels = [os.path.split(os.path.split(path)[0])[1] for path in valid_paths]
        elif mode == "multi":
            if labels_mapping is None:
                raise ValueError("Error: 'labels_mapping' is required for mode='multi'. Please provide a valid mapping.")
            labels = [labels_mapping.get(Path(path).name.split('_')[0], 'Unknown') for path in valid_paths]
        else:
            raise ValueError("Error: Invalid mode. Choose 'single' or 'multi'.")

        original_index = [
            data.loc[data[paths_col] == path, index_col].values[0]
            for path in valid_paths
        ]
        original_index = [int(index) for index in original_index]

        return pd.DataFrame({
            'Filepath': valid_paths,
            'Label': labels,
            'Original_Index': original_index
        })

    train_df = create_df('Train_Paths', 'Train_Index', mode, condition, labels_mapping) if 'Train_Paths' in data.columns else None
    valid_df = create_df('Validation_Paths', 'Validation_Index', mode, condition, labels_mapping) if 'Validation_Paths' in data.columns else None
    test_df = create_df('Test_Paths', 'Test_Index', mode, condition, labels_mapping) if 'Test_Paths' in data.columns else None

    if test_df is not None:
        return train_df, valid_df, test_df
    else:
        return train_df, valid_df

def visualize_images(df, count_img=25, nrows=5, ncols=5, title="Title",
                     fontsize=35, fontname="OPTITimes-Roman", paths='/img'):
    '''
    ฟังก์ชันนี้ใช้สำหรับแสดงผลรูปภาพแบบสุ่ม
    '''
    if count_img > len(df):
        raise ValueError("count_img cannot be greater than the number of images in the dataframe.")

    random_index = np.random.choice(len(df), count_img, replace=False)
    try:
        plt.rcParams['font.family'] = fontname
    except Exception as e:
        print(f"Font {fontname} not found. Using default font.")

    fig, axes = plt.subplots(nrows = nrows,
                          ncols = ncols,
                          figsize = (30, 30),
                          subplot_kw = {'xticks': [], 'yticks': []})
    fig.suptitle(title, fontsize=fontsize, fontweight='bold', y=1.0)

    for index, ax in enumerate(axes.flat):
        img_path = df.Filepath[random_index[index]]

        try:
            img = PIL.Image.open(img_path)
        except:
            print(f"Error opening image: {img_path}")
            continue

        ax.imshow(img)
        ax.set_title(df.Label[random_index[index]], fontsize=fontsize - 2)

    plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)
    plt.tight_layout(rect=[0, 0, 0, 0])
    plt.savefig(f"{paths}/Visualize_Images.png", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

def visualize_images_by_class(df, nrows=3, ncols=5, title="Title", fontsize=25,
                              fontname="OPTITimes-Roman", image_width=5, image_height=5, paths='/img'):
    '''
    ฟังก์ชันนี้ใช้สำหรับแสดงผลรูปภาพ โดยแสดง Preview 1 ภาพต่อ 1 คลาส
    '''
    class_samples = df.groupby('Label').apply(lambda x: x.sample(1)).reset_index(drop=True)

    count_img = len(class_samples)
    plt.rcParams['font.family'] = fontname

    fig, axes = plt.subplots(
        nrows = nrows,
        ncols = ncols,
        figsize=(ncols * image_width, nrows * image_height),
        subplot_kw = {'xticks': [], 'yticks': []}
    )

    for index, ax in enumerate(axes.flat):
        if index < count_img:
            img = PIL.Image.open(class_samples.Filepath[index])
            ax.imshow(img)
            ax.set_title(class_samples.Label[index], fontsize=fontsize)
        else:
            ax.axis('off')

    fig.text(0.5, 0.0, title, ha='center', fontsize=fontsize+10, fontweight='bold')

    plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)
    plt.tight_layout(rect=[0, 0, 0, 0])

    plt.savefig(f"{paths}/Visualize_Images_By_Class", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

def preview_augmented_images(df, nrows=2, ncols=4, index=0, title="Augmentation Sample",
                             fontsize=40, fontname="OPTITimes-Roman", paths="/img"):
    '''
    ฟังก์ชันนี้ใช้สำหรับแสดงผลรูปภาพที่ผ่านการ Augmentation โดยเปรียบเทียบภาพต้นฉบับและการ Augmentation ทั้ง 7 รูปแบบ
    ได้แก่
        พลิกภาพแนวตั้ง
        หมุนภาพ
        ซูมภาพ
        เลื่อนภาพแนวนอน
        เลื่อนภาพแนวตั้งแบบ
        เฉียงภาพ
        ปรับแสงภาพ

    ! สำหรับ Model ที่มีการ Preprocessing ในตัวโมเดลเองแล้วเช่น MobileNetV3 หรือยังไม่มีการ Rescale ใน ImageDataGenerator
    '''
    plt.rcParams['font.family'] = fontname
    img_path = df.iloc[index]['Filepath']
    label = df.iloc[index]['Label']

    img = keras.preprocessing.image.load_img(img_path, target_size=(224, 224))
    img_array = keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)

    augmentations = {
        "Horizontal Flip": tf.keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True),
        "Rotation 20 Degree": tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20),
        "Zoom 20%": tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2),
        "Width Shift 20%": tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.2),
        "Height Shift 20%": tf.keras.preprocessing.image.ImageDataGenerator(height_shift_range=0.2),
        "Shear 20 Degree": tf.keras.preprocessing.image.ImageDataGenerator(shear_range=0.2),
        "Brightness 90% - 110%": tf.keras.preprocessing.image.ImageDataGenerator(brightness_range=[0.9, 1.1])
    }

    fig, axes = plt.subplots(
        nrows = nrows,
        ncols = ncols,
        figsize = (30, 30),
        subplot_kw = {'xticks': [], 'yticks': []}
    )
    fig.suptitle(title + ' Augmentation Sample', fontsize=fontsize + 2, fontweight='bold', y=0.18)

    axes[0, 0].imshow(img_array[0].astype('uint8'))
    axes[0, 0].set_title(f"Original - {label}", fontsize=fontsize - 2)
    axes[0, 0].axis("off")

    for idx, (aug_name, aug_gen) in enumerate(augmentations.items(), start=1):
        augmented_images = aug_gen.flow(img_array, batch_size=1, shuffle=False)
        augmented_image = next(augmented_images)[0]
        row, col = divmod(idx, ncols)
        axes[row, col].imshow(augmented_image.astype('uint8'))
        axes[row, col].set_title(f"{aug_name}", fontsize=fontsize - 2)
        axes[row, col].axis("off")

    plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95, wspace=0.1, hspace=-0.4)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.savefig(f"{paths}/Augmentation_Sample", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

"ฟังก์ชันสำหรับทำงานกับโมเดลโดยเฉพาะ"
def save_path(otmz_name, dataset_name, rounds, model, seed):
    '''
    Function นี้ใช้สำหรับการ Save Model ตาม Path ที่ตั้งไว้
    มีหลายรูปแบบได้แก่
        -Weight Only (.h5) / (.weights.h5)
        -Model (.h5) (.keras)
        -JSON File (JSON)
        -TensorBoard logs
        -Epochs History File (CSV)
    '''
    # กำหนด path แบบสตริง
    base_path = f"/content/drive/MyDrive/projectPlant/modelTest2/{model}/{dataset_name}_{seed}({rounds})/{otmz_name}"
    # สร้างโฟลเดอร์หากยังไม่มี
    os.makedirs(base_path, exist_ok=True)
    model_file = f"{model}_{dataset_name}_{otmz_name}_{seed}({rounds})"

    if keras.__version__[0] == '2':
        name_weights_best = f"{model_file}_best.h5"
    elif keras.__version__[0] == '3':
        name_weights_best = f"{model_file}_best.keras"
    else:
        raise ValueError("Unsupported Keras version")

    # สร้างเส้นทางต่างๆ สำหรับการบันทึก
    checkpoint_path = os.path.join(base_path, name_weights_best)
    save_path_h5 = os.path.join(base_path, f"{model_file}.h5")
    save_path_keras = os.path.join(base_path, f"{model_file}.keras")
    save_path_json = os.path.join(base_path, f"{model_file}.json")
    save_path_history = os.path.join(base_path, f"{model_file}.csv")
    save_path_tensorboard = os.path.join(base_path, f"{model_file}_tensorboard_logs")

    return (checkpoint_path, save_path_h5, save_path_keras, save_path_json, save_path_history, save_path_tensorboard)

def save_epoch_history(history, file_path):
    '''
    Function นีใช้สำหรับการ Save Epoch History ในรูปแบบ CSV
    '''
    train_loss = history.history['loss']
    train_acc = history.history['accuracy']
    val_loss = history.history['val_loss']
    val_acc = history.history['val_accuracy']

    history_df = pd.DataFrame({
        'epoch': range(1, len(train_loss) + 1),
        'train_loss': train_loss,
        'train_acc': train_acc,
        'val_loss': val_loss,
        'val_acc': val_acc
    })

    history_df.to_csv(file_path, index=False)
    print(f"History has been saved to: {file_path}")

def save_model(model, save_path_h5, save_path_keras, save_path_json):
    '''
    Function นีใช้สำหรับการ Save Model ตาม Path ที่ได้ตั้งเอาไว้
    '''
    model.save(save_path_keras)
    model.save(save_path_h5)

    model_json = model.to_json()
    with open(save_path_json, 'w') as json_file:
        json_file.write(model_json)

    print(f"Model has been saved to: {save_path_keras}")
    print(f"Model has been saved to: {save_path_h5}")
    print(f"Model has been saved to: {save_path_json}")

def tr_plot(tr_data, start_epoch, fontsize=16, fontname="OPTITimes-Roman", paths="img"):
    # Plot the training and validation data
    tacc = tr_data.history['accuracy']
    tloss = tr_data.history['loss']
    vacc = tr_data.history['val_accuracy']
    vloss = tr_data.history['val_loss']
    Epoch_count=len(tacc) + start_epoch
    Epochs = []
    for i in range (start_epoch ,Epoch_count):
        Epochs.append(i+1)
    index_loss = np.argmin(vloss)#  this is the epoch with the lowest validation loss
    val_lowest = vloss[index_loss]
    index_acc = np.argmax(vacc)
    acc_highest = vacc[index_acc]

    plt.style.use('default')
    plt.rcParams['font.family'] = fontname
    sc_label = 'best epoch= '+ str(index_loss+1 +start_epoch)
    vc_label = 'best epoch= '+ str(index_acc + 1+ start_epoch)
    fig,axes = plt.subplots(nrows=1, ncols=2, figsize=(20,8))

    axes[0].plot(Epochs,tloss, 'blue', label='Training loss')
    axes[0].plot(Epochs,vloss,'red',label='Validation loss' )
    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)
    axes[0].set_title('Training and Validation Loss', fontsize=fontsize+2)
    axes[0].set_xlabel('Epochs', fontsize=fontsize)
    axes[0].set_ylabel('Loss', fontsize=fontsize)
    axes[0].legend(fontsize=fontsize-2)
    axes[0].tick_params(axis='x', labelsize=fontsize)
    axes[0].tick_params(axis='y', labelsize=fontsize)
    axes[0].legend(fontsize=fontsize)

    axes[1].plot (Epochs,tacc,'blue',label= 'Training Accuracy')
    axes[1].plot (Epochs,vacc,'red',label= 'Validation Accuracy')
    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)
    axes[1].set_title('Training and Validation Accuracy', fontsize=fontsize+2)
    axes[1].set_xlabel('Epochs', fontsize=fontsize)
    axes[1].set_ylabel('Accuracy', fontsize=fontsize)
    axes[1].legend(fontsize=fontsize-2)
    axes[1].tick_params(axis='x', labelsize=fontsize)
    axes[1].tick_params(axis='y', labelsize=fontsize)
    axes[1].legend(fontsize=fontsize)

    plt.tick_params(axis='both', labelsize=fontsize)
    plt.tight_layout

    plt.savefig(f"{paths}/Train_Val_Graph", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

def tr_plot_no_best_epoch(tr_data, start_epoch, fontsize=16, fontname="OPTITimes-Roman", paths='img'):
    # Plot the training and validation data
    tacc = tr_data.history['accuracy']
    tloss = tr_data.history['loss']
    vacc = tr_data.history['val_accuracy']
    vloss = tr_data.history['val_loss']
    Epoch_count=len(tacc) + start_epoch
    Epochs = []
    for i in range (start_epoch ,Epoch_count):
        Epochs.append(i+1)
    index_loss = np.argmin(vloss)#  this is the epoch with the lowest validation loss
    val_lowest = vloss[index_loss]
    index_acc = np.argmax(vacc)
    acc_highest = vacc[index_acc]

    plt.style.use('default')
    plt.rcParams['font.family'] = fontname
    sc_label = 'best epoch= '+ str(index_loss+1 +start_epoch)
    vc_label = 'best epoch= '+ str(index_acc + 1+ start_epoch)
    fig,axes = plt.subplots(nrows=1, ncols=2, figsize=(20,8))

    axes[0].plot(Epochs,tloss, 'blue', label='Training loss')
    axes[0].plot(Epochs,vloss,'red',label='Validation loss' )
    axes[0].set_title('Training and Validation Loss', fontsize=fontsize+2)
    axes[0].set_xlabel('Epochs', fontsize=fontsize)
    axes[0].set_ylabel('Loss', fontsize=fontsize)
    axes[0].legend(fontsize=fontsize-2)
    axes[0].tick_params(axis='x', labelsize=fontsize)
    axes[0].tick_params(axis='y', labelsize=fontsize)
    axes[0].legend(fontsize=fontsize)

    axes[1].plot (Epochs,tacc,'blue',label= 'Training Accuracy')
    axes[1].plot (Epochs,vacc,'red',label= 'Validation Accuracy')
    axes[1].set_title('Training and Validation Accuracy', fontsize=fontsize+2)
    axes[1].set_xlabel('Epochs', fontsize=fontsize)
    axes[1].set_ylabel('Accuracy', fontsize=fontsize)
    axes[1].legend(fontsize=fontsize-2)
    axes[1].tick_params(axis='x', labelsize=fontsize)
    axes[1].tick_params(axis='y', labelsize=fontsize)
    axes[1].legend(fontsize=fontsize)

    plt.tick_params(axis='both', labelsize=fontsize)
    plt.tight_layout

    plt.savefig(f"{paths}/Train_Val_Graph_No_Best", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

def lr_plot(tracker, history, fontsize=16 , fontname="OPTITimes-Roman", paths="/img"):
    epochs = range(1, len(tracker.learning_rates) + 1)
    lrs = tracker.learning_rates
    plt.rcParams['font.family'] = fontname

    plt.figure(figsize=(8, 6))
    plt.plot(epochs, lrs, marker='o', linestyle='-', color='blue', label='Learning Rate')
    plt.style.use('default')
    plt.title("Learning Rate vs Epochs", fontsize=fontsize)
    plt.xlabel("Epochs", fontsize=fontsize)
    plt.ylabel("Learning Rate", fontsize=fontsize)
    plt.xticks(fontsize=fontsize)
    plt.yticks(fontsize=fontsize)
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout()

    plt.legend()
    plt.savefig(f"{paths}/LearningRate_Graph", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

def plot_roc_curve(y_test, predicted, fontsize=16, fontname="OPTITimes-Roman", paths="/img"):
    label_binarizer = LabelBinarizer()
    y_test_binarized = label_binarizer.fit_transform(y_test)

    plt.rcParams['font.family'] = fontname
    plt.figure(figsize=(10, 8))

    for i in range(y_test_binarized.shape[1]):
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], predicted[:, i])
        roc_auc = auc(fpr, tpr)
        if roc_auc == 0.0:
            print(f"Skipping class {label_binarizer.classes_[i]} as AUC is 0.0")
            continue
        plt.plot(fpr, tpr, label=f'Class {label_binarizer.classes_[i]} (AUC = {roc_auc:.4f})')

    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlabel('False Positive Rate', fontsize=fontsize)
    plt.ylabel('True Positive Rate', fontsize=fontsize)
    plt.xticks(fontsize=fontsize)
    plt.yticks(fontsize=fontsize)
    plt.title('ROC Curve for Each Class', fontsize=fontsize)
    plt.legend(loc='lower right', fontsize=fontsize-4)

    plt.tight_layout()
    plt.savefig(f"{paths}/ROC_Curve", bbox_inches='tight', format='svg', dpi=300)
    plt.show()

def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=False, fontsize=18, fontname="OPTITimes-Roman", paths="/img"):
    accuracy = np.trace(cm) / float(np.sum(cm))
    misclass = 1 - accuracy
    sns.set(style="dark")

    if cmap is None:
        cmap = plt.get_cmap('Blues')

    plt.rcParams['font.family'] = fontname
    fig, ax = plt.subplots(figsize=(18, 14))
    ax.set_title(title, fontsize=fontsize+2, fontweight='bold')

    ax.spines['top'].set_linewidth(2)
    ax.spines['top'].set_color('black')
    ax.spines['right'].set_linewidth(2)
    ax.spines['right'].set_color('black')
    ax.spines['bottom'].set_linewidth(2)
    ax.spines['bottom'].set_color('black')
    ax.spines['left'].set_linewidth(2)
    ax.spines['left'].set_color('black')

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize confusion matrix
        thresh = 0.5
    else:
        thresh = cm.max() / 2.0

    cax = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    cbar = plt.colorbar(cax)
    cbar.ax.tick_params(labelsize=fontsize+3)
    cbar.set_ticks(np.linspace(np.min(cm), np.max(cm), 5))
    cbar.ax.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%.1f'))

    if target_names is not None:
        tick_marks = np.arange(len(target_names))
        ax.set_xticks(tick_marks)
        ax.set_xticklabels(target_names, rotation=45, ha='right', fontsize=fontsize)
        ax.set_yticks(tick_marks)
        ax.set_yticklabels(target_names, fontsize=fontsize)

    # Get the background color and adjust the text color accordingly
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        color_value = cm[i, j]  # Get the color intensity (in normalized terms)
        # Determine if background is dark or light by checking intensity
        color = "white" if color_value > thresh else "black"

        if normalize:
            ax.text(j, i, "{:0.4f}".format(cm[i, j]),
                horizontalalignment="center",
                color=color, fontsize=fontsize)
        else:
            ax.text(j, i, "{:,}".format(cm[i, j]),
                horizontalalignment="center",
                color=color, fontsize=fontsize+2)

    plt.tight_layout()
    ax.set_ylabel('True label', fontsize=fontsize, fontweight='bold')
    ax.set_xlabel('Predicted label\n Accuracy={:0.4f}; Misclass={:0.4f}'.format(accuracy, misclass), fontsize=fontsize+2, fontweight='bold')

    # Adjust subplots to make space for colorbar
    plt.style.use('default')

    if normalize:
        plt.savefig(f"{paths}/Confusion_Matrix_Normalize", bbox_inches='tight', format='svg', dpi=300)
    else:
        plt.savefig(f"{paths}/Confusion_Matrix", bbox_inches='tight', format='svg', dpi=300)

    plt.show()